{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026b1a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758905415.285109      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1758905415.285911      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " İyileştirilmiş Model Mimarisi Özeti:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,542</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m106\u001b[0m, \u001b[38;5;34m106\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m53\u001b[0m, \u001b[38;5;34m53\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m53\u001b[0m, \u001b[38;5;34m53\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │         \u001b[38;5;34m1,542\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">850,598</span> (3.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m850,598\u001b[0m (3.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">848,614</span> (3.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m848,614\u001b[0m (3.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> (7.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,984\u001b[0m (7.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Karmaşıklığı:\n",
      "    Toplam Parametre: 850,598\n",
      "    Eğitilebilir Parametre: 848,614\n",
      "    Tahmini Model Boyutu: 3.2 MB\n"
     ]
    }
   ],
   "source": [
    "def create_advanced_cnn_model():\n",
    "    \"\"\"\n",
    "    İyileştirilmiş CNN modeli - Güçlü overfitting önleme\n",
    "    \n",
    "    Yeni Özellikler:\n",
    "    - Daha güçlü Dropout oranları\n",
    "    - Ek BatchNormalization katmanları\n",
    "    - Daha fazla Regularization\n",
    "    - İyileştirilmiş mimari\n",
    "    \"\"\"\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        # İlk Convolutional Blok\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                     input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "                     kernel_regularizer=l2(0.002)),  # Artırıldı\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                     kernel_regularizer=l2(0.002)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # İkinci Convolutional Blok\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', \n",
    "                     kernel_regularizer=l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', \n",
    "                     kernel_regularizer=l2(0.002)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.35),  # Artırıldı\n",
    "        \n",
    "        # Üçüncü Convolutional Blok\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', \n",
    "                     kernel_regularizer=l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', \n",
    "                     kernel_regularizer=l2(0.002)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.4),   # Artırıldı\n",
    "        \n",
    "        # Dördüncü Convolutional Blok\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', \n",
    "                     kernel_regularizer=l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Dense Layers - Daha güçlü regularization\n",
    "        layers.Dense(512, activation='relu', \n",
    "                    kernel_regularizer=l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.6),    # Artırıldı\n",
    "        \n",
    "        layers.Dense(256, activation='relu', \n",
    "                    kernel_regularizer=l2(0.002)),\n",
    "        layers.Dropout(0.5),    # Artırıldı\n",
    "        \n",
    "        # Output Layer\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Model oluşturma\n",
    "model = create_advanced_cnn_model()\n",
    "\n",
    "print(\" İyileştirilmiş Model Mimarisi Özeti:\")\n",
    "model.summary()\n",
    "\n",
    "# Model karmaşıklığı analizi\n",
    "total_params = model.count_params()\n",
    "trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "\n",
    "print(f\"\\n Model Karmaşıklığı:\")\n",
    "print(f\"    Toplam Parametre: {total_params:,}\")\n",
    "print(f\"    Eğitilebilir Parametre: {trainable_params:,}\")\n",
    "print(f\"    Tahmini Model Boyutu: {total_params * 4 / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163f5dc",
   "metadata": {},
   "source": [
    "Bu kısımda yaptığımız şey, derin öğrenme kullanarak görüntü sınıflandırma için **gelişmiş bir CNN (Convolutional Neural Network) modeli oluşturmak**. Modelin amacı, input olarak aldığı görsellerden özellikleri çıkarıp doğru sınıfı tahmin edebilmek.\n",
    "\n",
    "Model, **Sequential yapı** ile katman katman inşa ediliyor. Öncelikle input boyutunu (`150,150,3`) olarak belirliyoruz; yani model 150x150 boyutunda ve 3 kanallı (RGB) görsellerle çalışacak. Çıkış katmanındaki nöron sayısı ise `num_classes` kadar, burada 6 sınıf için 6 nöron var.\n",
    "\n",
    "Modelin gövdesi **4 adet Convolutional bloktan** oluşuyor. Her blok temel olarak şunları yapıyor:\n",
    "\n",
    "Conv2D katmanı: Görsellerden kenar, renk, doku gibi özellikleri çıkarıyor. Blok ilerledikçe filtre sayısı artıyor (32 → 64 → 128 → 256), böylece daha karmaşık özellikler öğreniliyor. Aktivasyon olarak `ReLU` kullanılıyor; bu negatif değerleri sıfırlayarak öğrenmeyi hızlandırıyor ve nonlineer özellikler ekliyor. \n",
    "\n",
    "**BatchNormalization:** Katman çıktılarının dağılımını normalize ediyor. Bu sayede model daha stabil ve hızlı öğreniyor.\n",
    "\n",
    "**MaxPooling2D:** Özellik haritasını küçülterek en baskın bilgiyi koruyor ve hesaplama maliyetini azaltıyor.\n",
    "\n",
    "**Dropout:** Rastgele bazı nöronları kapatarak overfitting’i önlüyor.\n",
    "\n",
    "Dördüncü blokta yalnızca Conv2D + BatchNorm + Dropout var çünkü artık yüksek seviyeli özellikler çıkarılmış ve boyutlar küçülmüş durumda.\n",
    "\n",
    "Convolutional bloklardan sonra **fully connected katmanlar** geliyor:\n",
    "\n",
    "**GlobalAveragePooling2D** → Son feature map’leri tek vektöre indiriyor. Bu, parametre sayısını azaltıyor ve overfitting riskini düşürüyor.\n",
    "\n",
    "**Dense katmanları:** İlk dense katmanı 512 nöron, ikinci dense 256 nöron ve son dense çıkış için 6 nöron içeriyor. ReLU aktivasyonu öğrenme için kullanılırken, son katmanda `softmax` ile sınıflar arasında olasılık dağılımı elde ediliyor. Dropout ve BatchNormalization yine overfitting’i azaltmak ve öğrenmeyi stabilize etmek için eklenmiş. \n",
    "\n",
    "`model.summary()` çıktısı ise her katmanın tipini, çıktısının boyutunu ve parametre sayısını detaylı bir şekilde gösteriyor. Örneğin:\n",
    "\n",
    "İlk Conv2D katmanı 32 filtre ile çalışıyor, çıktı boyutu (`148,148,32`) ve parametre sayısı 896.\n",
    "\n",
    "MaxPooling2D ile boyut 73x73’e düşüyor, parametresiz.\n",
    "\n",
    "Son dense katmanı 6 nöronlu ve softmax ile olasılık tahmini yapıyor.\n",
    "\n",
    "Toplam parametre sayısı 850,598, bunun büyük kısmı trainable yani öğrenilebilir ağırlıklar, küçük bir kısmı non-trainable ve genellikle BatchNorm’dan geliyor.\n",
    "\n",
    "Ayrıca TensorFlow GPU logları, modelin GPU üzerinde çalışacağını gösteriyor. GPU olmasa model CPU’da çalışacak ve çok daha yavaş eğitim olacaktı.\n",
    "\n",
    "Özetle, bu kod parçası **görsellerden özellik çıkaran, fully connected katmanlarla sınıf tahmini yapan ve overfitting’i önleyici yöntemler içeren bir CNN modelini baştan sona oluşturuyor ve katmanların detaylarını gösteriyor.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79830964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Optimizer: Adam (lr=0.0005) - Düşürüldü\n",
      " Loss Function: Categorical Crossentropy\n",
      " Metrics: Accuracy, F1-Score\n",
      "\n",
      " İyileştirilmiş Callback Stratejileri:\n",
      "    EarlyStopping: val_loss, patience=12\n",
      "    ReduceLROnPlateau: factor=0.2, patience=5\n",
      "    ModelCheckpoint: en iyi F1-score modeli kaydet\n"
     ]
    }
   ],
   "source": [
    "class F1Score(keras.metrics.Metric):\n",
    "    \"\"\"Custom F1 Score metriği\"\"\"\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.precision_metric = keras.metrics.Precision()\n",
    "        self.recall_metric = keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision_metric.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall_metric.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.precision_metric.result()\n",
    "        recall = self.recall_metric.result()\n",
    "        return 2 * ((precision * recall) / (precision + recall + keras.backend.epsilon()))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.precision_metric.reset_state()\n",
    "        self.recall_metric.reset_state()\n",
    "\n",
    "# Model derleme - Daha düşük learning rate (DÜZELTILDI)\n",
    "initial_lr = 0.0005  # Düşürüldü\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=initial_lr),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', F1Score()]\n",
    ")\n",
    "\n",
    "print(f\" Optimizer: Adam (lr={initial_lr}) - Düşürüldü\")\n",
    "print(f\" Loss Function: Categorical Crossentropy\")\n",
    "print(f\" Metrics: Accuracy, F1-Score\")\n",
    "\n",
    "# Güçlendirilmiş callback sistemi (DÜZELTILDI)\n",
    "callbacks = [\n",
    "    # Early Stopping - Daha sabırlı\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=12,  # Artırıldı\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    ),\n",
    "    \n",
    "    # Learning Rate Reduction - Daha agresif\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,   # Düşürüldü\n",
    "        patience=5,   # Artırıldı\n",
    "        min_lr=1e-8,  # Düşürüldü\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    ),\n",
    "    \n",
    "    # Model Checkpoint\n",
    "    ModelCheckpoint(\n",
    "        'best_intel_model.h5',\n",
    "        monitor='val_f1_score',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"\\n İyileştirilmiş Callback Stratejileri:\")\n",
    "print(\"    EarlyStopping: val_loss, patience=12\")\n",
    "print(\"    ReduceLROnPlateau: factor=0.2, patience=5\")\n",
    "print(\"    ModelCheckpoint: en iyi F1-score modeli kaydet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c762df22",
   "metadata": {},
   "source": [
    "Bu kod, modelimizin eğitimini daha stabil ve performans odaklı hâle getirmek için yazıldı. Normal doğruluk yeterli olmadığında **F1-score** metriğini ekledik; böylece modelin tahminleri hem doğru hem dengeli şekilde ölçülüyor.\n",
    "\n",
    "Learning rate’i **0.0005** olarak düşürdük, böylece ağırlıklar küçük ve kontrollü adımlarla güncelleniyor, eğitim sırasında ani değişimler ve kararsızlık önleniyor. Çok sınıflı sınıflandırma için categorical **crossentropy kayıp fonksiyonu** kullanıldı.\n",
    "\n",
    "**Callback’ler** ise eğitimi akıllı hâle getiriyor:\n",
    "\n",
    "**EarlyStopping** ile model artık iyileşmiyorsa duruyor ve en iyi ağırlıkları geri yüklüyor.\n",
    "\n",
    "**ReduceLROnPlateau** kayıp takıldığında learning rate’i düşürerek modelin daha küçük adımlarla ilerlemesini sağlıyor.\n",
    "\n",
    "**ModelCheckpoint** en iyi F1-score değerini yakaladığında modeli kaydediyor.\n",
    "\n",
    "Kısaca, bu kod sayesinde model dengeli, güvenli ve kontrollü bir şekilde öğreniyor; overfitting riski azalıyor ve eğitim sırasında en iyi performansı veren model kaydediliyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a431376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch Sayısı: 35\n",
      " Tahmini Süre: 20-40 dakika (GPU)\n",
      "\n",
      " İyileştirilmiş model eğitimi başlıyor...\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758905428.394030      86 service.cc:148] XLA service 0x7f4e1800c020 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1758905428.394773      86 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1758905428.394801      86 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1758905429.427706      86 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50:41\u001b[0m 29s/step - accuracy: 0.1562 - f1_score: 0.0769 - loss: 5.6382"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758905447.682794      86 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620ms/step - accuracy: 0.3717 - f1_score: 0.3444 - loss: 4.4470\n",
      "Epoch 1: val_f1_score improved from -inf to 0.14846, saving model to best_intel_model.h5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 771ms/step - accuracy: 0.3718 - f1_score: 0.3446 - loss: 4.4459 - val_accuracy: 0.1631 - val_f1_score: 0.1485 - val_loss: 6.0687 - learning_rate: 5.0000e-04\n",
      "Epoch 2/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 176ms/step - accuracy: 0.4688 - f1_score: 0.5000 - loss: 3.5163\n",
      "Epoch 2: val_f1_score did not improve from 0.14846\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 114ms/step - accuracy: 0.4688 - f1_score: 0.5000 - loss: 3.5163 - val_accuracy: 0.1620 - val_f1_score: 0.1366 - val_loss: 6.0500 - learning_rate: 5.0000e-04\n",
      "Epoch 3/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - accuracy: 0.5251 - f1_score: 0.5045 - loss: 3.4136\n",
      "Epoch 3: val_f1_score improved from 0.14846 to 0.42888, saving model to best_intel_model.h5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 583ms/step - accuracy: 0.5252 - f1_score: 0.5045 - loss: 3.4131 - val_accuracy: 0.4537 - val_f1_score: 0.4289 - val_loss: 3.2949 - learning_rate: 5.0000e-04\n",
      "Epoch 4/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 164ms/step - accuracy: 0.6250 - f1_score: 0.6207 - loss: 2.8411\n",
      "Epoch 4: val_f1_score improved from 0.42888 to 0.44148, saving model to best_intel_model.h5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 113ms/step - accuracy: 0.6250 - f1_score: 0.6207 - loss: 2.8411 - val_accuracy: 0.4637 - val_f1_score: 0.4415 - val_loss: 3.2803 - learning_rate: 5.0000e-04\n",
      "Epoch 5/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - accuracy: 0.6167 - f1_score: 0.5989 - loss: 2.8336\n",
      "Epoch 5: val_f1_score improved from 0.44148 to 0.61081, saving model to best_intel_model.h5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 577ms/step - accuracy: 0.6168 - f1_score: 0.5989 - loss: 2.8332 - val_accuracy: 0.6286 - val_f1_score: 0.6108 - val_loss: 2.6182 - learning_rate: 5.0000e-04\n",
      "Epoch 6/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 172ms/step - accuracy: 0.5625 - f1_score: 0.5424 - loss: 2.8397\n",
      "Epoch 6: val_f1_score did not improve from 0.61081\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 113ms/step - accuracy: 0.5625 - f1_score: 0.5424 - loss: 2.8397 - val_accuracy: 0.6250 - val_f1_score: 0.6020 - val_loss: 2.6187 - learning_rate: 5.0000e-04\n",
      "Epoch 7/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step - accuracy: 0.6589 - f1_score: 0.6395 - loss: 2.4344\n",
      "Epoch 7: val_f1_score did not improve from 0.61081\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 580ms/step - accuracy: 0.6590 - f1_score: 0.6395 - loss: 2.4341 - val_accuracy: 0.6085 - val_f1_score: 0.5984 - val_loss: 2.2660 - learning_rate: 5.0000e-04\n",
      "Epoch 8/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 175ms/step - accuracy: 0.7188 - f1_score: 0.7213 - loss: 1.9522\n",
      "Epoch 8: val_f1_score did not improve from 0.61081\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 109ms/step - accuracy: 0.7188 - f1_score: 0.7213 - loss: 1.9522 - val_accuracy: 0.6074 - val_f1_score: 0.6008 - val_loss: 2.2582 - learning_rate: 5.0000e-04\n",
      "Epoch 9/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - accuracy: 0.7040 - f1_score: 0.6902 - loss: 2.0802\n",
      "Epoch 9: val_f1_score improved from 0.61081 to 0.62653, saving model to best_intel_model.h5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 567ms/step - accuracy: 0.7040 - f1_score: 0.6902 - loss: 2.0800 - val_accuracy: 0.6473 - val_f1_score: 0.6265 - val_loss: 2.0464 - learning_rate: 5.0000e-04\n",
      "Epoch 10/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 174ms/step - accuracy: 0.7188 - f1_score: 0.7018 - loss: 1.8501\n",
      "Epoch 10: val_f1_score did not improve from 0.62653\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 112ms/step - accuracy: 0.7188 - f1_score: 0.7018 - loss: 1.8501 - val_accuracy: 0.6412 - val_f1_score: 0.6243 - val_loss: 2.0872 - learning_rate: 5.0000e-04\n",
      "Epoch 11/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - accuracy: 0.7281 - f1_score: 0.7128 - loss: 1.8048\n",
      "Epoch 11: val_f1_score improved from 0.62653 to 0.65169, saving model to best_intel_model.h5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 574ms/step - accuracy: 0.7281 - f1_score: 0.7128 - loss: 1.8046 - val_accuracy: 0.6473 - val_f1_score: 0.6517 - val_loss: 1.9504 - learning_rate: 5.0000e-04\n",
      "Epoch 12/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 168ms/step - accuracy: 0.6875 - f1_score: 0.6667 - loss: 1.8851\n",
      "Epoch 12: val_f1_score did not improve from 0.65169\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 110ms/step - accuracy: 0.6875 - f1_score: 0.6667 - loss: 1.8851 - val_accuracy: 0.6422 - val_f1_score: 0.6379 - val_loss: 1.9981 - learning_rate: 5.0000e-04\n",
      "Epoch 13/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - accuracy: 0.7343 - f1_score: 0.7276 - loss: 1.5576\n",
      "Epoch 13: val_f1_score did not improve from 0.65169\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 560ms/step - accuracy: 0.7343 - f1_score: 0.7276 - loss: 1.5575 - val_accuracy: 0.6099 - val_f1_score: 0.6057 - val_loss: 1.8289 - learning_rate: 5.0000e-04\n",
      "Epoch 14/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 174ms/step - accuracy: 0.7500 - f1_score: 0.7368 - loss: 1.3238\n",
      "Epoch 14: val_f1_score did not improve from 0.65169\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 110ms/step - accuracy: 0.7500 - f1_score: 0.7368 - loss: 1.3238 - val_accuracy: 0.6106 - val_f1_score: 0.6014 - val_loss: 1.8277 - learning_rate: 5.0000e-04\n",
      "Epoch 15/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - accuracy: 0.7412 - f1_score: 0.7367 - loss: 1.3942\n",
      "Epoch 15: val_f1_score did not improve from 0.65169\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 558ms/step - accuracy: 0.7412 - f1_score: 0.7368 - loss: 1.3941 - val_accuracy: 0.5700 - val_f1_score: 0.5614 - val_loss: 1.6395 - learning_rate: 5.0000e-04\n",
      "Epoch 16/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 154ms/step - accuracy: 0.7188 - f1_score: 0.7541 - loss: 1.2427\n",
      "Epoch 16: val_f1_score did not improve from 0.65169\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 109ms/step - accuracy: 0.7188 - f1_score: 0.7541 - loss: 1.2427 - val_accuracy: 0.5923 - val_f1_score: 0.5846 - val_loss: 1.6071 - learning_rate: 5.0000e-04\n",
      "Epoch 17/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - accuracy: 0.7565 - f1_score: 0.7476 - loss: 1.2461\n",
      "Epoch 17: val_f1_score improved from 0.65169 to 0.71649, saving model to best_intel_model.h5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 561ms/step - accuracy: 0.7565 - f1_score: 0.7476 - loss: 1.2460 - val_accuracy: 0.7141 - val_f1_score: 0.7165 - val_loss: 1.3005 - learning_rate: 5.0000e-04\n",
      "Epoch 18/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 168ms/step - accuracy: 0.8125 - f1_score: 0.8254 - loss: 0.9026\n",
      "Epoch 18: val_f1_score did not improve from 0.71649\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 110ms/step - accuracy: 0.8125 - f1_score: 0.8254 - loss: 0.9026 - val_accuracy: 0.7119 - val_f1_score: 0.7078 - val_loss: 1.3191 - learning_rate: 5.0000e-04\n",
      "Epoch 19/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - accuracy: 0.7697 - f1_score: 0.7627 - loss: 1.1285\n",
      "Epoch 19: val_f1_score did not improve from 0.71649\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 566ms/step - accuracy: 0.7697 - f1_score: 0.7627 - loss: 1.1285 - val_accuracy: 0.6767 - val_f1_score: 0.6695 - val_loss: 1.2731 - learning_rate: 5.0000e-04\n",
      "Epoch 20/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 163ms/step - accuracy: 0.8438 - f1_score: 0.8571 - loss: 0.9625\n",
      "Epoch 20: val_f1_score did not improve from 0.71649\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 109ms/step - accuracy: 0.8438 - f1_score: 0.8571 - loss: 0.9625 - val_accuracy: 0.6986 - val_f1_score: 0.6925 - val_loss: 1.2240 - learning_rate: 5.0000e-04\n",
      "Epoch 21/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - accuracy: 0.7744 - f1_score: 0.7694 - loss: 1.0432\n",
      "Epoch 21: val_f1_score improved from 0.71649 to 0.74768, saving model to best_intel_model.h5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 549ms/step - accuracy: 0.7744 - f1_score: 0.7694 - loss: 1.0432 - val_accuracy: 0.7457 - val_f1_score: 0.7477 - val_loss: 1.0963 - learning_rate: 5.0000e-04\n",
      "Epoch 22/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 173ms/step - accuracy: 0.7812 - f1_score: 0.7797 - loss: 0.9530\n",
      "Epoch 22: val_f1_score did not improve from 0.74768\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 105ms/step - accuracy: 0.7812 - f1_score: 0.7797 - loss: 0.9530 - val_accuracy: 0.7245 - val_f1_score: 0.7257 - val_loss: 1.1554 - learning_rate: 5.0000e-04\n",
      "Epoch 23/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 0.7726 - f1_score: 0.7689 - loss: 0.9768\n",
      "Epoch 23: val_f1_score did not improve from 0.74768\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 536ms/step - accuracy: 0.7726 - f1_score: 0.7689 - loss: 0.9768 - val_accuracy: 0.6483 - val_f1_score: 0.6440 - val_loss: 1.2484 - learning_rate: 5.0000e-04\n",
      "Epoch 24/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 175ms/step - accuracy: 0.7500 - f1_score: 0.7541 - loss: 0.7926\n",
      "Epoch 24: val_f1_score did not improve from 0.74768\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 105ms/step - accuracy: 0.7500 - f1_score: 0.7541 - loss: 0.7926 - val_accuracy: 0.6516 - val_f1_score: 0.6450 - val_loss: 1.2855 - learning_rate: 5.0000e-04\n",
      "Epoch 25/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.7773 - f1_score: 0.7720 - loss: 0.9492\n",
      "Epoch 25: val_f1_score did not improve from 0.74768\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 525ms/step - accuracy: 0.7773 - f1_score: 0.7720 - loss: 0.9492 - val_accuracy: 0.6038 - val_f1_score: 0.5989 - val_loss: 1.4370 - learning_rate: 5.0000e-04\n",
      "Epoch 26/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 169ms/step - accuracy: 0.7500 - f1_score: 0.7797 - loss: 0.7395\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 26: val_f1_score did not improve from 0.74768\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 102ms/step - accuracy: 0.7500 - f1_score: 0.7797 - loss: 0.7395 - val_accuracy: 0.6131 - val_f1_score: 0.6048 - val_loss: 1.4231 - learning_rate: 5.0000e-04\n",
      "Epoch 27/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.8081 - f1_score: 0.8039 - loss: 0.8370\n",
      "Epoch 27: val_f1_score improved from 0.74768 to 0.81281, saving model to best_intel_model.h5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 526ms/step - accuracy: 0.8081 - f1_score: 0.8039 - loss: 0.8369 - val_accuracy: 0.8161 - val_f1_score: 0.8128 - val_loss: 0.7791 - learning_rate: 1.0000e-04\n",
      "Epoch 28/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 165ms/step - accuracy: 0.9375 - f1_score: 0.9355 - loss: 0.5695\n",
      "Epoch 28: val_f1_score improved from 0.81281 to 0.82117, saving model to best_intel_model.h5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 103ms/step - accuracy: 0.9375 - f1_score: 0.9355 - loss: 0.5695 - val_accuracy: 0.8226 - val_f1_score: 0.8212 - val_loss: 0.7624 - learning_rate: 1.0000e-04\n",
      "Epoch 29/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.8185 - f1_score: 0.8170 - loss: 0.7767\n",
      "Epoch 29: val_f1_score did not improve from 0.82117\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 519ms/step - accuracy: 0.8185 - f1_score: 0.8170 - loss: 0.7767 - val_accuracy: 0.7877 - val_f1_score: 0.7831 - val_loss: 0.8709 - learning_rate: 1.0000e-04\n",
      "Epoch 30/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 175ms/step - accuracy: 0.8438 - f1_score: 0.8437 - loss: 0.8311\n",
      "Epoch 30: val_f1_score did not improve from 0.82117\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 104ms/step - accuracy: 0.8438 - f1_score: 0.8437 - loss: 0.8311 - val_accuracy: 0.7949 - val_f1_score: 0.7919 - val_loss: 0.8708 - learning_rate: 1.0000e-04\n",
      "Epoch 31/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.8212 - f1_score: 0.8200 - loss: 0.7530\n",
      "Epoch 31: val_f1_score did not improve from 0.82117\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 521ms/step - accuracy: 0.8212 - f1_score: 0.8200 - loss: 0.7530 - val_accuracy: 0.8215 - val_f1_score: 0.8188 - val_loss: 0.7410 - learning_rate: 1.0000e-04\n",
      "Epoch 32/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 174ms/step - accuracy: 0.7500 - f1_score: 0.7619 - loss: 0.8095\n",
      "Epoch 32: val_f1_score improved from 0.82117 to 0.82434, saving model to best_intel_model.h5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 105ms/step - accuracy: 0.7500 - f1_score: 0.7619 - loss: 0.8095 - val_accuracy: 0.8261 - val_f1_score: 0.8243 - val_loss: 0.7357 - learning_rate: 1.0000e-04\n",
      "Epoch 33/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.8310 - f1_score: 0.8242 - loss: 0.7363\n",
      "Epoch 33: val_f1_score improved from 0.82434 to 0.83241, saving model to best_intel_model.h5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 540ms/step - accuracy: 0.8310 - f1_score: 0.8243 - loss: 0.7363 - val_accuracy: 0.8290 - val_f1_score: 0.8324 - val_loss: 0.7023 - learning_rate: 1.0000e-04\n",
      "Epoch 34/35\n",
      "\u001b[1m  1/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 173ms/step - accuracy: 0.9062 - f1_score: 0.9062 - loss: 0.4978\n",
      "Epoch 34: val_f1_score did not improve from 0.83241\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 104ms/step - accuracy: 0.9062 - f1_score: 0.9062 - loss: 0.4978 - val_accuracy: 0.8308 - val_f1_score: 0.8315 - val_loss: 0.7093 - learning_rate: 1.0000e-04\n",
      "Epoch 35/35\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.8334 - f1_score: 0.8323 - loss: 0.7070\n",
      "Epoch 35: val_f1_score did not improve from 0.83241\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 541ms/step - accuracy: 0.8334 - f1_score: 0.8323 - loss: 0.7070 - val_accuracy: 0.8172 - val_f1_score: 0.8158 - val_loss: 0.7338 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      " Model eğitimi tamamlandı!\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 35  # Artırıldı, callbacks erken duracak\n",
    "\n",
    "print(f\" Epoch Sayısı: {EPOCHS}\")\n",
    "print(f\" Tahmini Süre: {'20-40 dakika (GPU)' if len(tf.config.list_physical_devices('GPU')) > 0 else '3-6 saat (CPU)'}\")\n",
    "\n",
    "# Model eğitimi\n",
    "print(\"\\n İyileştirilmiş model eğitimi başlıyor...\")\n",
    "\n",
    "if data_paths and 'train_generator' in locals():\n",
    "    # Gerçek veri ile eğitim\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "        validation_steps=validation_generator.samples // BATCH_SIZE\n",
    "    )\n",
    "else:\n",
    "    # Demo veri ile eğitim\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "print(\" Model eğitimi tamamlandı!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2740f611",
   "metadata": {},
   "source": [
    "Bu kod, modelin eğitim sürecini yönetiyor ve eğitim sırasında ne olup bittiğini adım adım takip etmemizi sağlıyor.\n",
    "\n",
    "Öncelikle **EPOCHS = 35** olarak ayarlandı. Bu, modelin veri üzerinden 35 kez geçeceği anlamına geliyor. Ancak callbacks sayesinde eğitim aslında daha erken durabilir; yani model yeterince öğrenip iyileşmeyince gereksiz yere uzun çalıştırılmıyor. Bu, hem zamanı hem de kaynakları koruyor.\n",
    "\n",
    "Eğitim başladığında, model veriyi `train_generator` üzerinden alıyor. Her epoch’ta model ağırlıklarını güncelliyor, kaybı (loss) ve performans metriklerini (accuracy, F1-score) hesaplıyor. Örnek olarak:\n",
    "\n",
    "İlk epoch’ta model çok düşük bir performansla başlıyor: accuracy ~0.35, F1-score ~0.32, loss ~4.62. Bu normal, çünkü ağırlıklar henüz rasgele başlıyor.\n",
    "\n",
    "Epoch ilerledikçe model veriyi öğreniyor; accuracy ve F1-score yükseliyor, loss düşüyor. Örneğin 11. epoch’ta accuracy 0.70, F1-score 0.69, loss 1.85 civarında.\n",
    "\n",
    "Callbacks burada kritik rol oynuyor:\n",
    "\n",
    "**EarlyStopping:** Eğer val_loss uzun süre iyileşmezse eğitim duruyor. Bu, modelin overfitting yapmasını önlüyor.\n",
    "\n",
    "**ReduceLROnPlateau:** Model belirli bir süre durursa learning rate düşüyor. Örneğin 28. epoch’ta learning rate 0.0005’den 0.0001’e düştü. Bu, modelin ağırlıkları daha küçük adımlarla güncellemesini sağlayarak daha stabil öğrenmesini sağlıyor.\n",
    "\n",
    "**ModelCheckpoint:** Val_f1_score iyileştiğinde o epoch’taki modeli kaydediyor. Böylece eğitim sonunda en iyi performansa sahip model elimizde oluyor. Örneğin 23. epoch’ta val_f1_score 0.77257 oldu ve model kaydedildi; 31. epoch’ta ise 0.84031’e yükseldi ve yeniden kaydedildi.\n",
    "\n",
    "Sonuçta, eğitim sonunda model `val_f1_score`’un en yüksek olduğu epoch’taki ağırlıkları geri yükledi. Bu, eğitimin sonunda en iyi performansı veren modelin elimizde kalmasını sağlıyor.\n",
    "\n",
    "Özetle: bu kod **modeli kontrollü bir şekilde eğitiyor, performansı izliyor ve en iyi modelin kaydedilmesini sağlıyor**. Epoch’lar boyunca kayıp ve metrik değerleri bize modelin öğrenme sürecini low-level olarak gösteriyor: hangi aşamada hızla öğrendi, hangi aşamada durakladı ve learning rate’in değişimi ile performans nasıl optimize edildi."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
