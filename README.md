# Intel-Image-Classification---Deep-Learning-Projes

**Akbank Derin Ã–ÄŸrenme Bootcamp | EylÃ¼l 2025**

Bu proje, Intel Image Classification veri seti kullanÄ±larak CNN (Convolutional Neural Network) mimarisi ile 6 farklÄ± doÄŸal ve yapay ortamÄ±n sÄ±nÄ±flandÄ±rÄ±lmasÄ± Ã¼zerine Ã§alÄ±ÅŸÄ±lmÄ±ÅŸtÄ±r. Proje kapsamÄ±nda modern derin Ã¶ÄŸrenme teknikleri, overfitting kontrolÃ¼, model yorumlanabilirliÄŸi ve hiperparametre optimizasyonu uygulanmÄ±ÅŸtÄ±r.

##  Proje Ã–zeti

### Hedef
GÃ¶rÃ¼ntÃ¼leri 6 farklÄ± kategoriye ayÄ±rmak:
- **Buildings** (Binalar)
- **Forest** (Orman)
- **Glacier** (Buzul)
- **Mountain** (DaÄŸ)
- **Sea** (Deniz) 
- **Street** (Sokak)

### Ana SonuÃ§lar
- **Test Accuracy**: %82.03 
- **F1-Score**: 0.8203
- **Model Boyutu**: 3.2 MB (850,598 parametre)
- **Overfitting**: BaÅŸarÄ±yla kontrol edildi

##  Veri Seti Bilgileri

**Intel Image Classification Dataset** - Kaggle'dan alÄ±nan popÃ¼ler bir gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma veri seti.

### Veri DaÄŸÄ±lÄ±mÄ±
| SÄ±nÄ±f | EÄŸitim | Test |
|-------|---------|------|
| Mountain | 2,512 | 525 |
| Street | 2,382 | 501 |
| Buildings | 2,191 | 437 |
| Sea | 2,274 | 510 |
| Forest | 2,271 | 474 |
| Glacier | 2,404 | 553 |
| **Toplam** | **14,034** | **3,000** |

- GÃ¶rÃ¼ntÃ¼ boyutu: 224x224 piksel
- Batch size: 32
- Validation split: %20

##  KullanÄ±lan YÃ¶ntemler

### 1. Veri Ã–n Ä°ÅŸleme & ArtÄ±rma
Overfitting'i Ã¶nlemek ve model genelleme yeteneÄŸini artÄ±rmak iÃ§in gÃ¼Ã§lÃ¼ data augmentation teknikleri uygulandÄ±:

```python
# Uygulanan DÃ¶nÃ¼ÅŸÃ¼mler
- Rotation: Â±25Â°
- Width/Height Shift: Â±20%
- Horizontal Flip: Evet
- Zoom: Â±20%
- Brightness: %70-130
- Shear Transformation: Â±15Â°
```

### 2. CNN Model Mimarisi
Overfitting'e karÅŸÄ± geliÅŸmiÅŸ regularization teknikleriyle tasarlanmÄ±ÅŸ Ã¶zel CNN mimarisi:

**Temel BileÅŸenler:**
- 4 adet Convolutional blok (32, 64, 128, 256 filtre)
- Batch Normalization (her conv bloktan sonra)
- Dropout katmanlarÄ± (0.3 - 0.6 arasÄ±)
- L2 Regularization (0.002)
- Global Average Pooling
- Dense katmanlar (512, 256 nÃ¶ron)

**Aktivasyon FonksiyonlarÄ±:**
- Hidden layers: ReLU
- Output layer: Softmax (6 sÄ±nÄ±f iÃ§in)

### 3. EÄŸitim Stratejisi
Model eÄŸitimi iÃ§in akÄ±llÄ± callback sistemi kullanÄ±ldÄ±:

- **Learning Rate**: 0.0005 (kontrollÃ¼ Ã¶ÄŸrenme)
- **Optimizer**: Adam
- **Loss Function**: Categorical Crossentropy
- **Early Stopping**: Patience=12 (val_loss takibi)
- **Learning Rate Reduction**: Factor=0.2, Patience=5
- **Model Checkpoint**: En iyi F1-score'u kaydetme

### 4. Regularization Teknikleri
Overfitting'i Ã¶nlemek iÃ§in Ã§oklu strateji:
- Dropout oranlarÄ±: %30-60 arasÄ±
- L2 regularization: 0.002
- GÃ¼Ã§lÃ¼ data augmentation
- Early stopping
- Global average pooling

##  Model PerformansÄ±

### SÄ±nÄ±f BazÄ±nda SonuÃ§lar
| SÄ±nÄ±f | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| Buildings | 0.905 | 0.700 | 0.790 | 437 |
| Forest | 0.885 | 0.971 | 0.926 | 474 |
| Glacier | 0.806 | 0.772 | 0.789 | 553 |
| Mountain | 0.762 | 0.787 | 0.774 | 525 |
| Sea | 0.767 | 0.882 | 0.820 | 510 |
| Street | 0.839 | 0.808 | 0.823 | 501 |

### Genel Metrikler
- **Accuracy**: 82.03%
- **Macro Avg F1**: 0.820
- **Weighted Avg F1**: 0.819
- **Overfitting Durumu**: Kontrol altÄ±nda 

**En Ä°yi SÄ±nÄ±f**: Forest (%92.6 F1-score)  
**En Zorlu SÄ±nÄ±f**: Mountain (%77.4 F1-score)

##  Model YorumlanabilirliÄŸi

### Grad-CAM Analizi
Modelin hangi gÃ¶rÃ¼ntÃ¼ bÃ¶lgelerine odaklandÄ±ÄŸÄ±nÄ± anlamak iÃ§in Grad-CAM (Gradient-weighted Class Activation Mapping) tekniÄŸi uygulandÄ±. Bu sayede:

- Model kararlarÄ±nÄ±n gÃ¶rselleÅŸtirilmesi
- YanlÄ±ÅŸ sÄ±nÄ±flandÄ±rmalarÄ±n nedenlerinin anlaÅŸÄ±lmasÄ±
- Model gÃ¼venilirliÄŸinin deÄŸerlendirilmesi saÄŸlandÄ±

### Confusion Matrix Ä°Ã§gÃ¶rÃ¼leri
- Forest sÄ±nÄ±fÄ± en yÃ¼ksek recall'a sahip (0.971)
- Buildings sÄ±nÄ±fÄ±nÄ±n precision'Ä± en yÃ¼ksek (0.905)
- Mountain ve Glacier arasÄ±nda karÄ±ÅŸÄ±klÄ±k gÃ¶zlemlendi

##  Hiperparametre Optimizasyonu

Sistemli hiperparametre testi gerÃ§ekleÅŸtirildi:

**Test Edilen Parametreler:**
- Dropout oranlarÄ±: 0.3, 0.5
- Learning rate: 0.001, 0.0005
- Optimizer: Adam, RMSprop
- Batch size: 32, 64
- L2 regularization: 0.001, 0.002

**SonuÃ§**: Mevcut konfigÃ¼rasyon optimal performans saÄŸladÄ±.

##  Transfer Learning KarÅŸÄ±laÅŸtÄ±rmasÄ±

Custom CNN yanÄ±nda transfer learning de test edildi:
- Base model alternatifi oluÅŸturuldu
- 5 epoch ile hÄ±zlÄ± eÄŸitim yapÄ±ldÄ±
- Custom CNN ile performans karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±

##  Teknik Detaylar ve Ã–ÄŸrendiklerim

### Overfitting KontrolÃ¼
Bu projede en bÃ¼yÃ¼k meydan okuma overfitting'ti. Ã‡Ã¶zÃ¼m iÃ§in:
- Dropout oranlarÄ±nÄ± %30'dan %60'a Ã§Ä±kardÄ±m
- L2 regularization katsayÄ±sÄ±nÄ± 0.001'den 0.002'ye artÄ±rdÄ±m
- Data augmentation'Ä± gÃ¼Ã§lendirdim (shear transformation ekledim)
- Learning rate'i 0.001'den 0.0005'e dÃ¼ÅŸÃ¼rdÃ¼m

### Model Mimarisi KararlarÄ±
- **Global Average Pooling**: Flatten yerine GAP kullanarak parametre sayÄ±sÄ±nÄ± azalttÄ±m
- **Batch Normalization**: Her conv bloktan sonra ekleyerek gradient flow'u iyileÅŸtirdim
- **Progressive Dropout**: AÄŸÄ±n derinleÅŸtikÃ§e dropout oranÄ±nÄ± artÄ±rdÄ±m

### F1-Score Custom Metric
Accuracy yanÄ±nda F1-score da izledim Ã§Ã¼nkÃ¼:
- Ã‡ok sÄ±nÄ±flÄ± probleme daha uygun
- Precision ve recall dengesini gÃ¶steriyor
- Model selection iÃ§in daha gÃ¼venilir

##  KullanÄ±lan Teknolojiler

- **Framework**: TensorFlow/Keras 2.18.0
- **GPU**: Tesla T4 (Kaggle ortamÄ±)
- **Veri Ä°ÅŸleme**: ImageDataGenerator, OpenCV
- **GÃ¶rselleÅŸtirme**: Matplotlib, Seaborn
- **Metrikler**: Scikit-learn
- **Model Yorumlama**: Grad-CAM (custom implementation)

##  Proje YapÄ±sÄ±

```
ğŸ“‚ Notebook Ä°Ã§eriÄŸi
â”œâ”€â”€ 1. Veri KeÅŸfi ve Ä°statistikler
â”œâ”€â”€ 2. Veri GÃ¶rselleÅŸtirme  
â”œâ”€â”€ 3. Data Augmentation
â”œâ”€â”€ 4. CNN Model Mimarisi
â”œâ”€â”€ 5. Model EÄŸitimi
â”œâ”€â”€ 6. Performans DeÄŸerlendirmesi
â”œâ”€â”€ 7. Confusion Matrix Analizi
â”œâ”€â”€ 8. Grad-CAM GÃ¶rselleÅŸtirmesi
â”œâ”€â”€ 9. Hiperparametre Optimizasyonu
â”œâ”€â”€ 10. Transfer Learning
â”œâ”€â”€ 11. SonuÃ§lar ve Ä°yileÅŸtirmeler
â””â”€â”€ 12. Model Kaydetme
```
**Projenin tamamÄ± projenin Ã§ok bÃ¼yÃ¼k olmasÄ±ndan Ã¶tÃ¼rÃ¼ 4 parÃ§aya ayrÄ±larak githuba yÃ¼klenmiÅŸtir.**

##  Gelecek Ã‡alÄ±ÅŸmalar

### KÄ±sa Vadeli Ä°yileÅŸtirmeler
- **EfficientNet** veya **ResNet** ile transfer learning
- **Test Time Augmentation** (TTA) uygulama
- **Ensemble methods** ile model kombinasyonu
- **CutMix** ve **MixUp** augmentation teknikleri

### Orta Vadeli Hedefler
- **Streamlit** ile web uygulamasÄ± geliÅŸtirme
- **Docker** ile containerization
- **MLflow** ile model versioning
- **Gradio** ile interaktif demo

### Uzun Vadeli Vizyon
- **Object detection** ile sahne analizi
- **Semantic segmentation** iÃ§in pixel-level sÄ±nÄ±flandÄ±rma
- **Real-time inference** iÃ§in model optimization
- **Mobile deployment** iÃ§in quantization

##  Proje Linkleri

**Kaggle Notebook**: https://www.kaggle.com/code/szeynepdrk/intel-image-classificatin

**Kaggle Veriseti**: https://www.kaggle.com/datasets/puneet6060/intel-image-classification


##  SonuÃ§

Bu proje kapsamÄ±nda Intel Image Classification veri seti Ã¼zerinde %82 doÄŸruluk oranÄ±na sahip, dengeli ve yorumlanabilir bir CNN modeli geliÅŸtirildi. Overfitting baÅŸarÄ±yla kontrol edildi ve model gerÃ§ek dÃ¼nya uygulamalarÄ± iÃ§in hazÄ±r hale getirildi.

Proje boyunca derin Ã¶ÄŸrenme pipeline'Ä±nÄ±n tÃ¼m aÅŸamalarÄ±nÄ± deneyimleme fÄ±rsatÄ± buldum: veri Ã¶n iÅŸlemeden model deployment'a kadar. Ã–zellikle regularization teknikleri, callback sistemi ve model yorumlanabilirliÄŸi konularÄ±nda derinlemesine Ã¶ÄŸrendim.

---

**GeliÅŸtirici**: Zeynep SÄ±la Durak  
**Bootcamp**: Akbank Derin Ã–ÄŸrenme Bootcamp  
**Tarih**: EylÃ¼l 2025  
**Framework**: TensorFlow/Keras
